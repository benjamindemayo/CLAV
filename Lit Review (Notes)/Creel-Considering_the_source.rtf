{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 The identity of the person talking is likely to constrain the things that they talk about. Adults can use talker acoustics to make on-line predictions about upcoming spoken material (Van Berkum et al., 2008). However, this cue to meaning may take time to learn. Do preschoolers consider who is talking when they are comprehending spoken sentences? Experiment 1 showed that children and adults use vocal cues to talker identity in predicting the color of upcoming referents in spoken sentences. Experiment 2 showed that children and adults flexibly use acoustic cues to talker for first-person requests (\'93I want the square\'94) but reference to individuals for third-person requests (\'93Billy wants the square\'94). This suggests that children aged 3-5 years use who is talking to constrain the scope of reference in sentence processing, and know when this cue is likely to be useful.\
\
No two people sound alike. Some research indicates that this poses a challenge for language processing (Mullennix, Pisoni, \\& Martin, 1989; Nusbaum \\& Morin, 1992). However, it may also provide additional, helpful information to the comprehender. That is, knowing who is talking can provide useful information in processing spoken language. For instance, adult listeners make different predictions about upcoming information in a sentence depending on who is speaking it (Van Berkum, et al 2008), suggesting they have particular semantic associations with certain voice characteristics (e.g., a child\'92s voice vs. an adult\'92s voice). Thus, acoustic differences among talkers potentially have rich semantic associations (Geiselman \\& Crawley, 1983). But how long does it take the developing language learner to form and use these associations in comprehending language.\
\
It is not clear whether children store more nuanced semantic information in relation to speech acoustic. This information might be somewhat difficult to learn for two reasons. First, children may be working to ignore talker-related acoustics to extract the attributes related to meaning. Second, knowing who is talking may only be useful what the person is referring to himself (\'93I really need a vacation\'94) and not when talking about things irrelevant to himself (\'93It\'92s raining outside\'94). That is, talker information may only be a reliable cue to meaning in a limited set of circumstances.\
\
Children seem adept at processing prosodic information. Snedeker and Yuan (2008) showed that children were sensitive to a speaker\'92s intonational phrase boundaries in their interpretations of prepositions-phrase attachment. Ito, Jincho, Minai, Yamane, and Mazuka (2009) and Bibyk, Ito, Wagner, and Speer (2009) found that children as young as 6 years use pitch accent to constrain upcoming referents to a set of items contrasting on the pitch-accented dimension.
\b  These studies suggest that children attend to non-phonemic sound patterns that cue differences in meaning.\
\

\b0 Children seem to have more difficulty processing cues to vocal affect. Morton and Trehub (2001) found that when vocal affect conflicts with verbal content, children cannot ignore the verbal content when reporting the talker\'92s affect (reporting the first sentence as sounding happy even though its intonation was sad, and the second as sounding sad even though the intonation was happy). Nonetheless, recent work by Berman, Graham, and Chambers (2009) using eye tracking, a more sensitive, implicit measure, suggests that children associate positive and negative vocal affect cues with positively- and negatively-valenced pictures (e.g. intact vs. broken dolls).\
\

\b Children may be using these cues to make associations between sound properties and semantic attributes. For instance, pitch accent seems to semantically activate contrast sets. In the vocal emotion case, children might have associations between sad vocal cues and non-intact objects (Berman et al., 2009). This leaves open whether children are able to use non-phonemic acoustic information in the speech signal to make high-level inferences about the perspective taker.\
\
In sum, children show some ability to glean semantic information from two non-phonemic acoustic information sources, prosody and vocal affect. Thus, one might expect that children would gain semantic information from non-phonemic acoustic cues to talker as well. However, it is not clear that children can go so far as to use it to invoke a particular talker\'92s perspective.\
\

\b0 Children can use their knowledge of other individual\'92s color preferences, even when different from their own, to constrain the domain of reference.\
\
Both children and adults were able to use talker information early in the sentence to \'91predict\'92 the color of the upcoming referent: they looked more at blue things when Billy began talking, and at pink things when Anna began talking. This verifies that, in a relatively simple situation, children use talker identity to constrain the referential domain of upcoming sentential material. Children showed looking effects equivalent to adults, suggesting that they are as able as adults to integrate talker information with verb information (Anna + want = pink, Billy + want = blue). This may depend on event knowledge that children have obtained through lifetime experience, or based on experimental conditions, but in either case, children are able to exercise this knowledge.}