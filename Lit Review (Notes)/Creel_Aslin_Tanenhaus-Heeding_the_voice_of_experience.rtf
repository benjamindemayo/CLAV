{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 The paper examines the time course of lexical activation in the face of a non-phonemic cue, talker variation. We found that lexical competition was attenuated by consistent talker differences between words that would otherwise be lexical competitors. \
\
Targets with different-talker cohorts received greater fixation proportions than targets with same-talker cohorts, while the reverse was true for fixations to cohort competitors; there were fewer erroneous selections of competitor referents for different-talker competitors than same-talker competitors. Overall, these results support a view of the lexicon in which entries contain extra-phonemic information. Extensions of the artificial lexicon paradigm and developmental implications are discussed.\
\
The traditional view of speech perception emphasizes the role of phonetic and phonemic categories \'97 stressing the utility of only those acoustic-phonetic cues that conform to the phonological system of a particular natural language \'97 while invoking normalization processes to eliminate non-phonemic variation. Different talkers exhibit different fundamental frequencies (Van Lancker, Kreiman, & Wickens, 1985), speaking rates (Van Lancker et al., 1985), voice onset times (Allen, Miller, & DeSteno, 2002), etc. However, none of these factors influences word meaning. Phonemic categories, then, are key to identifying lexical entries, and other attributes of the speech signal are viewed as irrelevant and even detrimental to the process of spoken word recognition. This traditional perspective deals effectively with the first of two difficult problems in spoken word recognition: limited storage capacity. By storing only phonemic information, a large number of lexical entries can be represented with a small, compact set of symbols.\
\
Houston and Jusczyk (2000, 2003) suggests that, for early learners, induction is indeed difficult. They found that at 7.5 months of age infants have difficulty recognizing a word they have learned in one voice when that same word is spoken in another voice, whereas 3 month later they readily make this generalization.\
\
In contrast to models that discard acoustic variation, exemplar-based models of the lexicon (e.g., Goldinger, 1998) predict that lexical representations preserve acoustic detail, even detail that is not used in forming phonetic contrasts. Goldinger (1998) provided evidence from a shadowing task that was consistent with exemplar-specific encoding of words.\
\
Additional support for an exemplar theory of lexical representation comes from evidence that sub-phonemically detailed, rather than abstractly phonemic, representations characterize the lexicon. Priming (e.g., Andruski, Blumstein, & Burton, 1994) and eye-tracking studies (e.g., McMurray, Tanenhaus, & Aslin, 2002) have demonstrated gradient voice onset time (VOT) effects on lexical activation. That is, lexical items are not activated in all-or-none fashion, but are modulated by the degree of match to a (prototypical) VOT. Results like these are consistent with the role of a distributional learning mechanism (Maye, Werker, & Gerken, 2002) that stores acoustic detail: more frequent VOT exemplars are also more prototypical VOT values.\
\
Alternatively, if the lexicon is truly an acoustic store, in principle any sort of acoustic variability could signify lexical variation. One way to test this hypothesis is to take a non-phonemic property of the speech signal and make it lexically contrastive. If this sort of variation can cue lexical disambiguation, then it would provide strong support for an exemplar-based model of the lexicon (Goldinger, 1998; Hintzman, 1988).\
\
In sum, we know that talker variation is perceived; that it can affect task performance, and that it influences learning of novel (or altered) phonemes.\
\
In the present pair of experiments, we utilize the eye-tracking methodology to examine whether talker differences can be used by our participants, in this experimental context, as a cue to lexical identity.\
\
It is definitively true that a non-phonemic acoustic attribute, specifically talker variation, could be used in lexical disambiguation. Different-talker lexical items compete less with each other than same-talker lexical items do.\
\
A final interpretive issue concerns whether non-phonemic talker-specific information is part of the lexical representation, per se, or whether it is an example of paired-associate learning or context-dependent memory that naturally falls out of correlated cues in the input. One could ask whether we would see the same effects if we embedded consistent contextual sounds with word pairs (e.g., \'93couch\'94 always spoken with a car horn in the background, \'93cows\'94 always spoken with a slide whistle in the background), or even if we associated pictures with melodies that began identically but differed in timbre. Is talker information effective because it is part of the speech signal and is explicitly represented in the lexicon, or because it is an associated cue?\
\
Traditional view: the sound representation of words in the lexicon is limited to only those types of variation that are contrastive in some natural language. Higher-level lexical representations are limited to combinatory lexical information that affects distributional constraints on how words combine with one another, such as argument structure (Koenig, Mauner, & Bienvenue, 2003; Tanenhaus & Carlson, 1989) and perhaps more enriched event representations that participate in generative processes (e.g., Pustejovsky, 1991). \
\
Distributed view: a lexical entry is a coactivated set of representations that encompass all properties of a word, such as the word\'92s phonological form, motor actions (Hauk, Johnsurde, & Pulvermuller, 2004), visual speech information (McGurk & MacDonald, 1976), and combinatory information such as verb argument structure (e.g., MacDonald, Pearlmutter, & Seidenberg, 1994; Tanenhaus, Carlson, & Trueswell, 1989). These properties are correlated with one another, and will upon presentation coactivate with each other.\
\
Evidence from functional brain imaging supports the notion of distributed representations (e.g., Hauk et al., 2004; Martin, Wiggs, Ungerleider, & Haxby, 1996). Recently, Hauk et al. had participants passively read verbs for actions executed by different body parts (lick, pick, kick; tongue, hand, foot). They found that the three verb types (tongue-, hand-, and foot-words) elicited differential activation in bilateral primary motor cortex, varying according to the body part used. This suggests that lexical semantic representations for these verbs have distributed patterns of activation that differ according to actual motoric functions associated with those verbs. Moreover, there seems to be no principled way to cordon off these motor representations from the rest of the \'91lexical\'92 information associated with these words. Thus, lexical entries may include similarly distributed types of information. If talker information, car horns, and slide whistles correlate with certain words, then these pieces of information will be coactivated with all of the other parts of the word\'92s representation. Rather than dividing information related to a  word into \'91lexical\'92 and \'91extra lexical\'92, all information associated with a word may be part of its lexical entry.}