{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 Recent work demonstrates that listeners utilize talker-specific information in the speech signal to inform real-time language processing. However, there are multiple representational levels at which this may take place. Listeners might use acoustic cues in the speech signal to access the talker\'92s identity and information about what they tend to talk about, which then immediately constrains processing.\
\
Alternatively, or simultaneously, listeners might compare the signal to acoustically-detailed representations of words, without awareness of the talker\'92s identity. This paper explores the circumstances under which listeners utilize talker-specific information.\
\
The speech signal contains not only phonemic information but important non-phonemic information: prosody, vocal emotional cues, and acoustic correlates of talker identity (Creel, Aslin, & Tanenhaus, 2008; Nygaard, Sommers & Pisoni, 1994; Palmeri, Goldinger, & Pisoni, 1993).\
\
Talker-varying acoustic cues can be specific enough to identify the talker (Fellowes, Remez, & Rubin, 1997; Remez, Fellowes, & Rubin, 1997, etc.) but even when they do not identify the exact individual, they can provide information about the talker\'92s sex and age (Peterson & Barney, 1952). These are just some of many indexical cues provided by the speech signal (Ladefoged & Broadbent, 1957).\
\
Indexical information is linked to what the talker is likely to say, and how they are likely to say it.\
\
In a semantic-encoding account, listeners use this acoustic indexical information in the speech signal to identify the person talking, and know that person likes to talk about particular topics; listeners would in this case use acoustically-specific information in the speech signal to activate representations of people. Those representations of people, then, are linked to knowledge about how (the listener believes) those people think and act. The listener\'92s inference about the person may not necessarily be accurate, but is based on that listener\'92s beliefs about particular individuals or groups. This can be referred to as talker-semantic information \'97 using acoustic cues in the speech stream to encode or access semantic information about a talker.\
\
By contrast, acoustic-match encoding effects seem to be strongest for individuals who are inexperienced in a language: children (Houston & Jusczyk, 2000, 2003; Schmale & Seidl, 2009).\
\
Some have suggested that adults maintain neurologically and cognitively distinct representations for word-forms and for talkers, even though both sets of representations are derived from the same signal. One might also imagine that the same representations contain talker and word information, but that listeners allocate attention to different dimensions of the representations depending on the task, as described by Nosofsky (1989). It may be that adults can attend to who is talking when this information is relevant to the task at hand \'97 comprehension \'97 but may not attend when this information is deemed uninformative.\
\
One might expect talker identity to constrain online processing much in the same way that sentence context can constrain processing. For instance, Dahan and Tanenhaus (2004) found that verbs like \'93snack on\'94 in a sentence such as \'93He likes to snack on candy\'94 can short-circuit phonological competition with an implausible competitor like \'91candle\'92 with looks to the candy exceeding looks to the candle even before the onset of \'91candy.\'92 \
\
Activating knowledge about the identity might work in exactly the same way, with knowledge about the talker and their mental state constraining reference before the phonological form of a word is available.\
\
Work by Richtsmeier, Gerken, Goffman, and Hogan (2009) finds that preschoolers also benefit from high-talker-variability learning. This has been shown in L2-learning adults as well. Hearing a range of different talkers producing the same word or accent results in a more generalizable representation. This suggests that across a wide age range, listeners can be sensitive to the talker-specific aspects of speech.\
\
If talker information semantically constrains processing in the same way that sentence context does, then talker-specific effects should show up prior to word onset. This should happen because indexical information is available well before word onset, but word information is only available at or after word onset.\
\
The data in the paper suggests that listeners need high cue diagnosticity to spontaneously utilize talker-specific information in neutral sentence frames, but that awareness of talker-picture mappings need not play a large role. Specifically, listeners only showed strong talker-specific looking patterns during the lead-in sentence when talker information diagnosed the target on 100% of trials. When talker was only diagnostic on 50% of trials (and uninformative on the rest), listeners showed relatively weak evidence of talker-specific looking patterns, even if a given participant saw only four shapes, which should have provided a relatively low memory load.\
\
Creel was interested in both listeners\'92 use of acoustic-match information, where word forms are stored in acute acoustic detail, and their use of talker-semantic information \'97 linkages between talkers and the things they talked about. The studies found evidence for both types of information.\
\
Creel Tumlin 2011 showed that listeners may store acoustic-match information with little effort, but store talker-semantic information when it is attended or is highly diagnostic of a response, and perhaps when memory demands are at a minimum.\
\
The study demonstrates that listeners encode (or utilize) what seems to be talker-semantic information very differently depending on the task they are performing.\
\
When the listener expects talker identity to be useful, either because it is necessary to succeed in the task (Experiment 3) or because it is an extremely-reliable response cue (Experiment 4), the listener will use talker-semantic information in on-line processing. It should be kept in mind that the \'91task utility\'92 of talker-semantic information in the real world may change from situation to situation, and may be greater than that demonstrated in our study.\
\
At a broader levee, the current study suggests that the acoustic details of spoken language have effects at multiple levels in comprehension, which vary from situation to situation. This provides valuable input to our understanding of how listeners use highly-detailed information in the speech signal by demonstrating that talker-specific encoding may occur at multiple loci, but potentially under different circumstances.\
\
It is convenient to dichotomize variability in the speech signal into rapidly-varying phonemic characteristics (voice onset time, formant transitions) vs. slow-varying talker-related characteristics (f0, formant frequency range), which would neatly lateralize speech leftward and talker rightward. Extending this to our proposed acoustic/semantic distinction, identification of talkers might proceed from coarse-grained analyses, and identification of words might proceed from fine-grained analyses.\
\
Complicating this tidy picture, talker variability cross-cuts both coarse and fine acoustic time scales, and listeners can use both coarse and fine-grained information to identify talkers (Allen et al., 2003; Fellowes et al., 1997; Remez et al., 1997). This suggests that talker representations and word representations, even if they function separately, must share some information. This might mean that talker representations, while including some fine-grained information, are biased toward coarse-grained information more strongly than fine-grained information, with the reverse being true for speech processing.\
\
Unlike adults, children match acoustic characteristics of the talkers in reproducing recognized words (Ryalls & Pisoni, 1997). This might mean that children are somewhat more sensitive than adults to acoustic-match effects in word learning, with a gradual lessening \'97 but not disappearance\'97 of acoustic-match effects stretching across the course of development, rather than just the first year of life.\
\
References:\
Allen et al., 2003\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 Creel, Aslin, & Tanenhaus, 2008 \
Dahan & Tanenhaus, 2004\
Fellowes et al., 1997\
\pard\pardeftab720

\f1\fs26 \cf0 Ladefoged and Broadbent (1957): Information conveyed by vowels
\f0\fs24 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural
\cf0 Nygaard, Sommers & Pisoni, 1994\
Palmeri, Goldinger, & Pisoni, 1993\
Peterson & Barney, 1952\
Remez et al., 1997}